# Computer-Vision-Hand-Recognition-for-Robot-Control- 
This project presents a robot control system that utilizes gestures and combines computer vision techniques with transfer learning methodologies. Hand gestures are captured by the system using a 1080p HD webcam and processed with the OpenCV library in Python. To isolate and extract hand regions from the input image, several image pre-processing methods, such as Otsu thresholding and adaptive thresholding, are utilized. A convolution neural network is used to train upon the hand images. The challenges faced with few images are presented and solution for the same is given with more count of images with diverse environments. Various transfer learning models are analysed to find the best combination of base model with the fine tuning of remaining model.To test how hand gesture recognition can be integrated with robotic movement, a simplified game prototype has been created. To simulate movement in a gaming environment, the robotic control aspect of the system uses the Pygame library in Python. The navigation of the simulated robot can be controlled by users' hands using hand gestures that are mapped to specific movements within the gaming environment.Computer vision and transfer learning are used to demonstrate effective gesture-based robotic control for accurate gaming interaction in this project.**
